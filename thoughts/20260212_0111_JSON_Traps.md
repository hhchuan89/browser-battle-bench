# Deep Think: JSON Straitjacket & Logic Traps
**Date:** 2026-02-12 01:11
**Focus:** Feasibility of strict JSON enforcement and Logic Trap design in WebLLM environment.

## 1. Feasibility Analysis (可行性分析)

### JSON Straitjacket (JSON 拘束衣)
*   **The Problem:** Small models (Phi-3, Gemma-2b, Qwen-1.5-Chat) running in browser often struggle with strict format adherence. They like to include conversational filler ("Here is the JSON you asked for...").
*   **Technical Constraint:** WebLLM/MLC-LLM has support for grammar-guided generation, but enabling it on the client-side WebGPU runtime can be computationally expensive or buggy compared to server-side vLLM.
*   **Feasibility Rating:** **High**, but requires custom implementation.
*   **Strategy:**
    *   **Strict Mode:** Don't rely solely on the model's good will. Implement a "Streaming Validator" that monitors the token stream.
    *   **Fail Fast:** If the model outputs a non-JSON character (outside of whitespace) at the start, kill the generation immediately. This visualizes the "Straitjacket" concept perfectly—the model hits an invisible wall.

### Logic Traps (逻辑陷阱)
*   **The Problem:** Browser models are usually highly quantized (q4f16_1). Quantization often degrades reasoning capabilities ("Logic") before it degrades fluency.
*   **The Trap Design:** Traps must be short. We cannot afford 2000-token context prompts on a user's GPU without risking OOM or 5-minute wait times.
*   **Feasibility Rating:** **Medium**. Requires careful prompt engineering for small context windows.
*   **Verification:** How to judge the logic?
    *   *Option A:* Multiple Choice (A/B/C) parsed via Regex. (Boring but reliable).
    *   *Option B:* "Keyphrase Hunting". The reasoning must contain specific intermediate steps.

## 2. Implementation Path (实现路径)

### Tech Stack
*   **Core:** React + Vite + TypeScript.
*   **AI Engine:** `mlc-ai/web-llm` (Best WebGPU support currently).
*   **UI:** "Cyberpunk/Terminal" aesthetic to fit the "Battle/Arena" theme.

### Architecture: "The Gauntlet"
1.  **Stage 1: The Jailer (JSON Test)**
    *   Prompt: Generate a recursive JSON structure describing a fictional ecosystem.
    *   Validator: `ajv` (JSON Schema validator).
    *   Visual: A progress bar that turns red and shatters if validation fails.
2.  **Stage 2: The Sphinx (Logic Test)**
    *   Prompt: Short riddles designed to trigger hallucinations.
    *   Example: "Which is heavier: 1kg of feathers or 1000g of steel?" (Simple) -> "Sally has 3 brothers..." (Medium).

## 3. Evolution (演进与取舍)

*   **New Idea (Keep):** **"Visualizing the Fail"**. Don't just show a score. Show *where* the model broke the JSON. Highlight the exact comma it missed. Make the failure humiliating for the model.
*   **Cut (Kill):** **"Local Ollama Support" (for MVP)**.
    *   *Reasoning:* The project goal is "Edge-First". Relying on Ollama makes it just another UI wrapper. The "Wow factor" comes from *running in the browser tab*. Focus 100% on WebGPU integration first.
*   **Adjustment:** Start with **Qwen-2.5-Coder-7B** or **Llama-3.2-3B** as the benchmark targets. They are small enough for many laptops but smart enough to have a chance.
