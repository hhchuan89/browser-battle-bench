# Thought Log: JSON Straitjacket & Logic Traps
**Date:** 2026-02-12 01:41
**Topic:** Feasibility of Strict Output Constraints & Logic Puzzles in WebLLM

## 1. Feasibility Analysis (可行性分析)

### JSON Straitjacket (JSON 拘束衣)
*   **The Challenge:** Quantized browser models (e.g., Llama-3-8B-q4f16_1) are notorious for "yapping" before outputting code/JSON ("Sure, here is the JSON...").
*   **WebLLM Limitations:** Does the current WebLLM engine support strict grammar-constrained sampling (BNF/Regex constraints) natively and efficiently?
    *   *Risk:* If we rely purely on prompt engineering, the failure rate for < 8B models will be high.
    *   *Mitigation:* We must implement a "Verifier Loop" in JS.
        1.  **Prompt:** "Output ONLY JSON."
        2.  **Receive:** Text.
        3.  **Clean:** Extract content between first `{` and last `}`.
        4.  **Parse:** `JSON.parse()`.
        5.  **Fail?** Feed error back to model: "JSON.parse failed: Unexpected token at... Fix it."
    *   *Scoring:* The score decreases with every retry. 0 retries = Perfect.

### Logic Traps (逻辑陷阱)
*   **The Challenge:** Small models tend to be sycophantic (agreeing with user's false premises).
*   **Performance:** Loading a model for a simple logic puzzle is heavy.
*   **Optimization:** We need to batch these traps. Load the model once, run a gauntlet of 10 traps in one context window (or resetting context efficiently).
*   **Verification:** How do we judge the answer?
    *   *Deterministic:* Use strict regex matching for the correct answer key.
    *   *LLM-as-Judge:* Too heavy to run *another* model to judge the first one on a user's laptop.
    *   *Decision:* Stick to deterministic answers for v1. (e.g., Multiple Choice or exact number extraction).

## 2. Implementation Path (实现路径)

### Tech Stack
*   **Core:** React + Vite (Speed is king).
*   **Engine:** `@mlc-ai/web-llm`.
*   **State:** Zustand (Simpler than Redux for benchmarking state).

### The "Straitjacket" Module (Draft Logic)
```typescript
interface StraitjacketChallenge {
  schema: object; // The target JSON schema
  difficulty: 'loose' | 'strict' | 'hell';
}

async function runStraitjacket(model, challenge) {
  let attempts = 0;
  const maxAttempts = 3;
  
  while (attempts < maxAttempts) {
    const response = await model.generate(prompt);
    const json = extractJSON(response); // Heuristic extractor
    if (validateSchema(json, challenge.schema)) {
      return { success: true, attempts };
    }
    // Feed error back into context for next turn
    attempts++;
  }
  return { success: false };
}
```

## 3. Evolution & Culling (演进与删减)

*   **New Idea (The "Memory Leak" Test):**
    *   Can we stress test the browser's garbage collection? Run the model continuously for 1 hour summarizing text until the tab crashes?
    *   *Verdict:* Add to "Torture Chamber" category. High risk but funny.

*   **Culling (Kill List):**
    *   *Idea:* "Multi-Agent Debate Tournament".
    *   *Reasoning:* Running *two* distinct models (or swapping weights) in WebGPU is currently too slow/memory-intensive for average consumer hardware. It will crash the browser.
    *   *Decision:* Kill it. Focus on **Single Model vs. Hard Constraints**.

## Next Steps
1.  Initialize the React project structure.
2.  Create a "Hello World" WebLLM test page.
3.  Draft the first 5 "Logic Trap" questions (must be solvable by GPT-4, failable by Llama-2-7b).
